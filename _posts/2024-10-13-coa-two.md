---
layout: post
title: 计算机组成原理学习笔记（二）
subtitle: Notes Pt.2 for review
tag: [Computer Organization and Architecture]
cover-img: /assets/img/miku.jpg
share-img: /assets/img/miku.jpg
thumbnail-img: /assets/img/miku.jpg
author: LiPtP
mathjax: true
---

{: .box-note}
This is a summary note of the course "Computer Organization and Architecture" by Professor *William Stallings*. 

The remaining contents is organized as:
- Chapter 4 (*Pt. II*)
    - Elements of Cache Design
        - Cache Addresses
        - Cache Size
        - Mapping Function
        - Replacement Algorithm
        - Write Policy
        - Line/Block Size
        - Number of Caches


-------

# Chapter 4 (Part II): Elements of Cache Design
## Cache Addresses
There are some concepts:
1. Virtual Memory: Virtual memory is a technique that allows programs to run without running out of physical memory. It works by mapping the virtual memory addresses to physical memory addresses.
2. Hardware Memory Management Unit (MMU): The MMU is a hardware device that translates virtual memory addresses to physical memory addresses. It is inserted **between Processor and Main Memory.**
3. Logical Cache is located between the MMU and **the processor**.
4. Physical Cache is located between the MMU and **the main memory**.

## Cache Size

{: .box-success}
*We would like the size of the cache to be small enough so that the overall average cost per bit is close to that of main memory alone and large enough so that the overall average access time is close to that of the cache alone.*

## Mapping Function
a means is needed for determining which **main memory block** currently occupies a cache
line. The choice of the mapping function dictates how the cache is organized.

So there are three main mapping functions:
- Direct-mapped: *Each block is mapped to a single cache line in main memory.*
 
The corresponding way is: $$i = j mod m$$, where m is the number of cache lines and j is the main memory block number. Here is an example:

<br/>
    ![Direct Mapping](/assets/img/COA-images/Direct-Mapping.png){: .mx-auto.d-block :}
    <br/>

There are some figures to remember. Note that we will specify **s** as the length of the tag and line, **r** as the line size, and **w** as the bits of the word. 

1. Address length = (s+w) bits, where the **most significant s bits** specify a memory block, while the **least significant w bits** specify a word within the block.
2. Number of addressable units = $$2^{s+w}$$ words.
3. Block size = Line size = $$2^w$$ words.
4. Number of blocks in main memory = $$2^{s}$$.
5. Number of cache lines = m = $$2^r$$.
6. size of tag = s-r bits.

It is very easy to implement, but it leads to fixed cache location for any given block. Thus, when two blocks are mapped to the same cache line, they will be evicted together.

- Associative Mapping

It overcomes the disadvantage of direct mapping by permitting each main memory block to be loaded into any line of the cache. In this way, the content in the main memory includes only **tag** and **word**.
3. Set-associative: Each cache line is mapped to any block in main memory.
# Review Questions
## Questions


**Question 4.5**
Consider a 32-bit microprocessor that has an on- chip 16-kB four- way set- associative cache. Assume that the cache has a line size of four 32-bit words. Draw a block diagram of this cache showing its organization and how the different address fields are used to determine a cache hit/miss. Where in the cache is the word from memory location ABCDE8F8 mapped?

{: .box-note}

**Question 4.6**
Given the following specifications for an external cache memory: four- way set associative; line size of two 16-bit words; able to accommodate a total of 4K 32-bit words from main memory; used with a 16-bit processor that issues 24-bit addresses. Design the cache structure with all pertinent information and show how it interprets the processor’s addresses.

{: .box-note}

**Question 4.7**
The Intel 80486 has an on- chip, unified cache. It contains 8 kB and has a four- way
set- associative organization and a block length of four 32-bit words. The cache is organized into 128 sets. There is a single “line valid bit” and three bits, B0, B1, and B2 (the “LRU” bits), per line. On a cache miss, the 80486 reads a 16-byte line from main memory in a bus memory read burst. Draw a simplified diagram of the cache and show how the different fields of the address are interpreted.

## Answers for reference